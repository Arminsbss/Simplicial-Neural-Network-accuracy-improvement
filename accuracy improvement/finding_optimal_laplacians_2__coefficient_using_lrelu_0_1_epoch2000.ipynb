{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "finding_optimal_laplacians-2-_coefficient_using_lrelu-0_1_epoch2000.ipynb",
      "authorship_tag": "ABX9TyPCr27z2XIs45+MUzhgOOm1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arminsbss/Simplicial-Neural-Network/blob/Arminsbss-learning-rate-and-epochs/accuracy%20improvement/finding_optimal_laplacians_2__coefficient_using_lrelu_0_1_epoch2000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGnOA_G72-Wm",
        "outputId": "42eb0b97-54ea-4b61-9b0a-f6b875ed8795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simplicial_neural_networks'...\n",
            "remote: Enumerating objects: 339, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 339 (delta 50), reused 48 (delta 48), pack-reused 280\u001b[K\n",
            "Receiving objects: 100% (339/339), 2.42 MiB | 5.25 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/stefaniaebli/simplicial_neural_networks.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "\n",
        "Iteration=1\n",
        "random_numbers=[]\n",
        "accuracies_for_0_laplacian=[]\n",
        "accuracies_for_1_laplacian=[]\n",
        "accuracies_for_2_laplacian=[]\n",
        "\n",
        "while Iteration<=1:\n",
        "  %cd /content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
        "  laplacians = np.load('150250_laplacians.npy',allow_pickle=True)\n",
        "\n",
        "  random_number = random.random()\n",
        "  random_numbers.append(random_number)\n",
        "  line_length = 7  # Adjust this value based on how many elements we want in each line\n",
        "  counter = 0\n",
        "  for i in range(4697):\n",
        "    if laplacians[2].data[i]<0:\n",
        "      print(i,'. ',laplacians[2].data[i],end='->')\n",
        "      laplacians[2].data[i] = max(0.1 * laplacians[2].data[i], laplacians[2].data[i])\n",
        "      print(laplacians[2].data[i],end=', ')\n",
        "      counter+=1\n",
        "      if counter == line_length:\n",
        "        print()  # Print a new line\n",
        "        counter = 0  # Reset the counter\n",
        "  # for i in range(3285):\n",
        "  #   laplacians[2].data[(laplacians[2].row==i) & (laplacians[2].col==i)]+=1\n",
        "\n",
        "  %cd /content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
        "  np.save('150250_laplacians.npy', laplacians)\n",
        "\n",
        "  %cd /content/simplicial_neural_networks\n",
        "  !python ./experiments/impute_citations.py ./data/s2_3_collaboration_complex ./experiments/output 150250 30\n",
        "\n",
        "  #calculating accuracy for the 0-laplacian\n",
        "  %cd /content/simplicial_neural_networks/experiments/output\n",
        "\n",
        "  folder_path = '/content/simplicial_neural_networks/experiments/output'\n",
        "\n",
        "  files = os.listdir(folder_path)\n",
        "  files.sort()\n",
        "\n",
        "  prediction = []\n",
        "  actual = []\n",
        "\n",
        "  for filename in os.listdir('.'):\n",
        "    if filename.startswith('prediction') and filename.endswith('0.txt'):\n",
        "      with open(filename, 'r') as f:\n",
        "          numbers_str = f.read()\n",
        "      numbers_list = numbers_str.split()\n",
        "      numbers_int = list(map(float, numbers_list))\n",
        "      prediction += numbers_int\n",
        "    elif filename.startswith('actual') and filename.endswith('0.txt'):\n",
        "      with open(filename, 'r') as f:\n",
        "          numbers_str = f.read()\n",
        "      numbers_list = numbers_str.split()\n",
        "      numbers_int = list(map(float, numbers_list))\n",
        "      actual += numbers_int\n",
        "  prediction = [round(x, 0) for x in prediction]\n",
        "  actual = [round(x, 0) for x in actual]\n",
        "\n",
        "  accuracy = accuracy_score(actual, prediction)\n",
        "  accuracies_for_0_laplacian.append(accuracy)\n",
        "  print(\"We set this random number: \",random_number)\n",
        "  print(f'Accuracy for 0-laplacian: {accuracy}')\n",
        "\n",
        "  #calculating accuracy for the 1-laplacian\n",
        "  prediction = []\n",
        "  actual = []\n",
        "\n",
        "  for filename in os.listdir('.'):\n",
        "      if filename.startswith('prediction') and filename.endswith('1.txt'):\n",
        "          with open(filename, 'r') as f:\n",
        "              numbers_str = f.read()\n",
        "          numbers_list = numbers_str.split()\n",
        "          numbers_int = list(map(float, numbers_list))\n",
        "          prediction += numbers_int\n",
        "      elif filename.startswith('actual') and filename.endswith('1.txt'):\n",
        "          with open(filename, 'r') as f:\n",
        "              numbers_str = f.read()\n",
        "          numbers_list = numbers_str.split()\n",
        "          numbers_int = list(map(float, numbers_list))\n",
        "          actual += numbers_int\n",
        "  prediction = [round(x, 0) for x in prediction]\n",
        "  actual = [round(x, 0) for x in actual]\n",
        "\n",
        "  accuracy = accuracy_score(actual, prediction)\n",
        "  accuracies_for_1_laplacian.append(accuracy)\n",
        "  print(f'Accuracy for 1-laplacian: {accuracy}')\n",
        "\n",
        "  #calculating accuracy for the 2-laplacian\n",
        "  prediction = []\n",
        "  actual = []\n",
        "\n",
        "  for filename in os.listdir('.'):\n",
        "      if filename.startswith('prediction') and filename.endswith('2.txt'):\n",
        "          with open(filename, 'r') as f:\n",
        "              numbers_str = f.read()\n",
        "          numbers_list = numbers_str.split()\n",
        "          numbers_int = list(map(float, numbers_list))\n",
        "          prediction += numbers_int\n",
        "      elif filename.startswith('actual') and filename.endswith('2.txt'):\n",
        "          with open(filename, 'r') as f:\n",
        "              numbers_str = f.read()\n",
        "          numbers_list = numbers_str.split()\n",
        "          numbers_int = list(map(float, numbers_list))\n",
        "          actual += numbers_int\n",
        "  prediction = [round(x, 0) for x in prediction]\n",
        "  actual = [round(x, 0) for x in actual]\n",
        "\n",
        "  accuracy = accuracy_score(actual, prediction)\n",
        "  accuracies_for_2_laplacian.append(accuracy)\n",
        "  print(f'Accuracy for 2-laplacian: {accuracy}')\n",
        "\n",
        "  max_accuracy0 = max(accuracies_for_0_laplacian)\n",
        "  max_index0 = accuracies_for_0_laplacian.index(max_accuracy0)\n",
        "  print(f\"The maximum accuracy for 0 laplacian is: {max_accuracy0} and its index is: {max_index0} with coefficient {random_numbers[max_index0]}\")\n",
        "\n",
        "  max_accuracy1 = max(accuracies_for_1_laplacian)\n",
        "  max_index1 = accuracies_for_1_laplacian.index(max_accuracy1)\n",
        "  print(f\"The maximum accuracy for 1 laplacian is: {max_accuracy1} and its index is: {max_index1} with coefficient {random_numbers[max_index1]}\")\n",
        "\n",
        "  max_accuracy2 = max(accuracies_for_2_laplacian)\n",
        "  max_index2 = accuracies_for_2_laplacian.index(max_accuracy2)\n",
        "  print(f\"The maximum accuracy for 2 laplacian is: {max_accuracy2} and its index is: {max_index2} with coefficient {random_numbers[max_index2]}\")\n",
        "\n",
        "  Iteration+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffVIBHwdMFX9",
        "outputId": "92fc3587-3eda-4ba3-8bd5-6715d2214829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "75 .  -1.0->-0.1, 76 .  -1.0->-0.1, 81 .  -1.0->-0.1, 82 .  -1.0->-0.1, 132 .  -1.0->-0.1, 300 .  -1.0->-0.1, 301 .  -1.0->-0.1, \n",
            "302 .  -1.0->-0.1, 303 .  -1.0->-0.1, 304 .  -1.0->-0.1, 309 .  -1.0->-0.1, 310 .  -1.0->-0.1, 311 .  -1.0->-0.1, 312 .  -1.0->-0.1, \n",
            "313 .  -1.0->-0.1, 314 .  -1.0->-0.1, 320 .  -1.0->-0.1, 321 .  -1.0->-0.1, 322 .  -1.0->-0.1, 323 .  -1.0->-0.1, 324 .  -1.0->-0.1, \n",
            "328 .  -1.0->-0.1, 329 .  -1.0->-0.1, 330 .  -1.0->-0.1, 452 .  -1.0->-0.1, 467 .  -1.0->-0.1, 468 .  -1.0->-0.1, 473 .  -1.0->-0.1, \n",
            "474 .  -1.0->-0.1, 667 .  -1.0->-0.1, 673 .  -1.0->-0.1, 909 .  -1.0->-0.1, 910 .  -1.0->-0.1, 911 .  -1.0->-0.1, 912 .  -1.0->-0.1, \n",
            "973 .  -1.0->-0.1, 974 .  -1.0->-0.1, 975 .  -1.0->-0.1, 976 .  -1.0->-0.1, 977 .  -1.0->-0.1, 981 .  -1.0->-0.1, 982 .  -1.0->-0.1, \n",
            "983 .  -1.0->-0.1, 1112 .  -1.0->-0.1, 1113 .  -1.0->-0.1, 1114 .  -1.0->-0.1, 1115 .  -1.0->-0.1, 1184 .  -1.0->-0.1, 1190 .  -1.0->-0.1, \n",
            "1396 .  -1.0->-0.1, 1397 .  -1.0->-0.1, 1398 .  -1.0->-0.1, 1399 .  -1.0->-0.1, 1400 .  -1.0->-0.1, 1404 .  -1.0->-0.1, 1405 .  -1.0->-0.1, \n",
            "1406 .  -1.0->-0.1, 1435 .  -1.0->-0.1, 1441 .  -1.0->-0.1, 1526 .  -1.0->-0.1, 1768 .  -1.0->-0.1, 1778 .  -1.0->-0.1, 1779 .  -1.0->-0.1, \n",
            "1780 .  -1.0->-0.1, 1781 .  -1.0->-0.1, 1782 .  -1.0->-0.1, 1783 .  -1.0->-0.1, 1784 .  -1.0->-0.1, 1785 .  -1.0->-0.1, 1786 .  -1.0->-0.1, \n",
            "1787 .  -1.0->-0.1, 1788 .  -1.0->-0.1, 1809 .  -1.0->-0.1, 1810 .  -1.0->-0.1, 1811 .  -1.0->-0.1, 1812 .  -1.0->-0.1, 1813 .  -1.0->-0.1, \n",
            "1862 .  -1.0->-0.1, 1863 .  -1.0->-0.1, 1870 .  -1.0->-0.1, 1874 .  -1.0->-0.1, 1875 .  -1.0->-0.1, 1882 .  -1.0->-0.1, 1885 .  -1.0->-0.1, \n",
            "1886 .  -1.0->-0.1, 1893 .  -1.0->-0.1, 1895 .  -1.0->-0.1, 1896 .  -1.0->-0.1, 1903 .  -1.0->-0.1, 1917 .  -1.0->-0.1, 1918 .  -1.0->-0.1, \n",
            "1919 .  -1.0->-0.1, 1920 .  -1.0->-0.1, 1927 .  -1.0->-0.1, 1930 .  -1.0->-0.1, 1933 .  -1.0->-0.1, 1936 .  -1.0->-0.1, 1941 .  -1.0->-0.1, \n",
            "1944 .  -1.0->-0.1, 1947 .  -1.0->-0.1, 1950 .  -1.0->-0.1, 1953 .  -1.0->-0.1, 1954 .  -1.0->-0.1, 1960 .  -1.0->-0.1, 1962 .  -1.0->-0.1, \n",
            "1963 .  -1.0->-0.1, 1974 .  -1.0->-0.1, 1977 .  -1.0->-0.1, 1980 .  -1.0->-0.1, 1983 .  -1.0->-0.1, 1986 .  -1.0->-0.1, 1989 .  -1.0->-0.1, \n",
            "1992 .  -1.0->-0.1, 1995 .  -1.0->-0.1, 1997 .  -1.0->-0.1, 2000 .  -1.0->-0.1, 2003 .  -1.0->-0.1, 2006 .  -1.0->-0.1, 2008 .  -1.0->-0.1, \n",
            "2009 .  -1.0->-0.1, 2015 .  -1.0->-0.1, 2017 .  -1.0->-0.1, 2018 .  -1.0->-0.1, 2027 .  -1.0->-0.1, 2028 .  -1.0->-0.1, 2034 .  -1.0->-0.1, \n",
            "2035 .  -1.0->-0.1, 2036 .  -1.0->-0.1, 2037 .  -1.0->-0.1, 2038 .  -1.0->-0.1, 2042 .  -1.0->-0.1, 2045 .  -1.0->-0.1, 2048 .  -1.0->-0.1, \n",
            "2049 .  -1.0->-0.1, 2050 .  -1.0->-0.1, 2051 .  -1.0->-0.1, 2052 .  -1.0->-0.1, 2053 .  -1.0->-0.1, 2084 .  -1.0->-0.1, 2087 .  -1.0->-0.1, \n",
            "2088 .  -1.0->-0.1, 2089 .  -1.0->-0.1, 2090 .  -1.0->-0.1, 2091 .  -1.0->-0.1, 2092 .  -1.0->-0.1, 2093 .  -1.0->-0.1, 2098 .  -1.0->-0.1, \n",
            "2099 .  -1.0->-0.1, 2100 .  -1.0->-0.1, 2101 .  -1.0->-0.1, 2102 .  -1.0->-0.1, 2104 .  -1.0->-0.1, 2119 .  -1.0->-0.1, 2120 .  -1.0->-0.1, \n",
            "2121 .  -1.0->-0.1, 2122 .  -1.0->-0.1, 2126 .  -1.0->-0.1, 2127 .  -1.0->-0.1, 2128 .  -1.0->-0.1, 2129 .  -1.0->-0.1, 2130 .  -1.0->-0.1, \n",
            "2146 .  -1.0->-0.1, 2147 .  -1.0->-0.1, 2148 .  -1.0->-0.1, 2149 .  -1.0->-0.1, 2152 .  -1.0->-0.1, 2153 .  -1.0->-0.1, 2157 .  -1.0->-0.1, \n",
            "2164 .  -1.0->-0.1, 2176 .  -1.0->-0.1, 2185 .  -1.0->-0.1, 2186 .  -1.0->-0.1, 2187 .  -1.0->-0.1, 2189 .  -1.0->-0.1, 2190 .  -1.0->-0.1, \n",
            "2191 .  -1.0->-0.1, 2196 .  -1.0->-0.1, 2197 .  -1.0->-0.1, 2198 .  -1.0->-0.1, 2200 .  -1.0->-0.1, 2201 .  -1.0->-0.1, 2202 .  -1.0->-0.1, \n",
            "2206 .  -1.0->-0.1, 2207 .  -1.0->-0.1, 2208 .  -1.0->-0.1, 2210 .  -1.0->-0.1, 2211 .  -1.0->-0.1, 2212 .  -1.0->-0.1, 2215 .  -1.0->-0.1, \n",
            "2216 .  -1.0->-0.1, 2217 .  -1.0->-0.1, 2218 .  -1.0->-0.1, 2219 .  -1.0->-0.1, 2235 .  -1.0->-0.1, 2236 .  -1.0->-0.1, 2237 .  -1.0->-0.1, \n",
            "2238 .  -1.0->-0.1, 2240 .  -1.0->-0.1, 2241 .  -1.0->-0.1, 2242 .  -1.0->-0.1, 2249 .  -1.0->-0.1, 2250 .  -1.0->-0.1, 2251 .  -1.0->-0.1, \n",
            "2252 .  -1.0->-0.1, 2253 .  -1.0->-0.1, 2254 .  -1.0->-0.1, 2256 .  -1.0->-0.1, 2257 .  -1.0->-0.1, 2258 .  -1.0->-0.1, 2265 .  -1.0->-0.1, \n",
            "2266 .  -1.0->-0.1, 2267 .  -1.0->-0.1, 2274 .  -1.0->-0.1, 2275 .  -1.0->-0.1, 2276 .  -1.0->-0.1, 2277 .  -1.0->-0.1, 2278 .  -1.0->-0.1, \n",
            "2279 .  -1.0->-0.1, 2280 .  -1.0->-0.1, 2288 .  -1.0->-0.1, 2289 .  -1.0->-0.1, 2301 .  -1.0->-0.1, 2302 .  -1.0->-0.1, 2303 .  -1.0->-0.1, \n",
            "2304 .  -1.0->-0.1, 2305 .  -1.0->-0.1, 2306 .  -1.0->-0.1, 2313 .  -1.0->-0.1, 2321 .  -1.0->-0.1, 2322 .  -1.0->-0.1, 2323 .  -1.0->-0.1, \n",
            "2335 .  -1.0->-0.1, 2336 .  -1.0->-0.1, 2337 .  -1.0->-0.1, 2338 .  -1.0->-0.1, 2339 .  -1.0->-0.1, 2348 .  -1.0->-0.1, 2354 .  -1.0->-0.1, \n",
            "2358 .  -1.0->-0.1, 2362 .  -1.0->-0.1, 2371 .  -1.0->-0.1, 2380 .  -1.0->-0.1, 2381 .  -1.0->-0.1, 2385 .  -1.0->-0.1, 2389 .  -1.0->-0.1, \n",
            "2395 .  -1.0->-0.1, 2411 .  -1.0->-0.1, 2412 .  -1.0->-0.1, 2413 .  -1.0->-0.1, 2415 .  -1.0->-0.1, 2416 .  -1.0->-0.1, 2417 .  -1.0->-0.1, \n",
            "2424 .  -1.0->-0.1, 2425 .  -1.0->-0.1, 2426 .  -1.0->-0.1, 2428 .  -1.0->-0.1, 2429 .  -1.0->-0.1, 2430 .  -1.0->-0.1, 2433 .  -1.0->-0.1, \n",
            "2434 .  -1.0->-0.1, 2435 .  -1.0->-0.1, 2436 .  -1.0->-0.1, 2437 .  -1.0->-0.1, 2438 .  -1.0->-0.1, 2441 .  -1.0->-0.1, 2454 .  -1.0->-0.1, \n",
            "2455 .  -1.0->-0.1, 2456 .  -1.0->-0.1, 2457 .  -1.0->-0.1, 2459 .  -1.0->-0.1, 2460 .  -1.0->-0.1, 2461 .  -1.0->-0.1, 2463 .  -1.0->-0.1, \n",
            "2464 .  -1.0->-0.1, 2465 .  -1.0->-0.1, 2467 .  -1.0->-0.1, 2483 .  -1.0->-0.1, 2484 .  -1.0->-0.1, 2485 .  -1.0->-0.1, 2487 .  -1.0->-0.1, \n",
            "2488 .  -1.0->-0.1, 2489 .  -1.0->-0.1, 2495 .  -1.0->-0.1, 2496 .  -1.0->-0.1, 2510 .  -1.0->-0.1, 2511 .  -1.0->-0.1, 2512 .  -1.0->-0.1, \n",
            "2513 .  -1.0->-0.1, 2514 .  -1.0->-0.1, 2518 .  -1.0->-0.1, 2519 .  -1.0->-0.1, 2520 .  -1.0->-0.1, 2521 .  -1.0->-0.1, 2522 .  -1.0->-0.1, \n",
            "2526 .  -1.0->-0.1, 2527 .  -1.0->-0.1, 2528 .  -1.0->-0.1, 2529 .  -1.0->-0.1, 2530 .  -1.0->-0.1, 2535 .  -1.0->-0.1, 2536 .  -1.0->-0.1, \n",
            "2541 .  -1.0->-0.1, 2542 .  -1.0->-0.1, 2545 .  -1.0->-0.1, 2546 .  -1.0->-0.1, 2549 .  -1.0->-0.1, 2558 .  -1.0->-0.1, 2567 .  -1.0->-0.1, \n",
            "2568 .  -1.0->-0.1, 2569 .  -1.0->-0.1, 2572 .  -1.0->-0.1, 2573 .  -1.0->-0.1, 2576 .  -1.0->-0.1, 2577 .  -1.0->-0.1, 2599 .  -1.0->-0.1, \n",
            "2600 .  -1.0->-0.1, 2601 .  -1.0->-0.1, 2602 .  -1.0->-0.1, 2603 .  -1.0->-0.1, 2604 .  -1.0->-0.1, 2606 .  -1.0->-0.1, 2607 .  -1.0->-0.1, \n",
            "2610 .  -1.0->-0.1, 2620 .  -1.0->-0.1, 2621 .  -1.0->-0.1, 2622 .  -1.0->-0.1, 2624 .  -1.0->-0.1, 2625 .  -1.0->-0.1, 2627 .  -1.0->-0.1, \n",
            "2628 .  -1.0->-0.1, 2643 .  -1.0->-0.1, 2644 .  -1.0->-0.1, 2645 .  -1.0->-0.1, 2646 .  -1.0->-0.1, 2659 .  -1.0->-0.1, 2660 .  -1.0->-0.1, \n",
            "2661 .  -1.0->-0.1, 2662 .  -1.0->-0.1, 2665 .  -1.0->-0.1, 2677 .  -1.0->-0.1, 2682 .  -1.0->-0.1, 2694 .  -1.0->-0.1, 2703 .  -1.0->-0.1, \n",
            "2716 .  -1.0->-0.1, 2717 .  -1.0->-0.1, 2718 .  -1.0->-0.1, 2719 .  -1.0->-0.1, 2721 .  -1.0->-0.1, 2722 .  -1.0->-0.1, 2723 .  -1.0->-0.1, \n",
            "2724 .  -1.0->-0.1, 2725 .  -1.0->-0.1, 2726 .  -1.0->-0.1, 2727 .  -1.0->-0.1, 2728 .  -1.0->-0.1, 2729 .  -1.0->-0.1, 2730 .  -1.0->-0.1, \n",
            "2731 .  -1.0->-0.1, 2732 .  -1.0->-0.1, 2733 .  -1.0->-0.1, 2734 .  -1.0->-0.1, 2735 .  -1.0->-0.1, 2740 .  -1.0->-0.1, 2741 .  -1.0->-0.1, \n",
            "2742 .  -1.0->-0.1, 2748 .  -1.0->-0.1, 2749 .  -1.0->-0.1, 2750 .  -1.0->-0.1, 2751 .  -1.0->-0.1, 2752 .  -1.0->-0.1, 2753 .  -1.0->-0.1, \n",
            "2754 .  -1.0->-0.1, 2755 .  -1.0->-0.1, 2756 .  -1.0->-0.1, 2757 .  -1.0->-0.1, 2758 .  -1.0->-0.1, 2762 .  -1.0->-0.1, 2763 .  -1.0->-0.1, \n",
            "2764 .  -1.0->-0.1, 2765 .  -1.0->-0.1, 2766 .  -1.0->-0.1, 2767 .  -1.0->-0.1, 2768 .  -1.0->-0.1, 2769 .  -1.0->-0.1, 2770 .  -1.0->-0.1, \n",
            "2771 .  -1.0->-0.1, 2772 .  -1.0->-0.1, 2776 .  -1.0->-0.1, 2777 .  -1.0->-0.1, 2778 .  -1.0->-0.1, 2779 .  -1.0->-0.1, 2780 .  -1.0->-0.1, \n",
            "2781 .  -1.0->-0.1, 2782 .  -1.0->-0.1, 2783 .  -1.0->-0.1, 2784 .  -1.0->-0.1, 2785 .  -1.0->-0.1, 2786 .  -1.0->-0.1, 2943 .  -1.0->-0.1, \n",
            "2944 .  -1.0->-0.1, 2945 .  -1.0->-0.1, 2946 .  -1.0->-0.1, 2947 .  -1.0->-0.1, 2948 .  -1.0->-0.1, 2949 .  -1.0->-0.1, 2954 .  -1.0->-0.1, \n",
            "2955 .  -1.0->-0.1, 3001 .  -1.0->-0.1, 3002 .  -1.0->-0.1, 3003 .  -1.0->-0.1, 3004 .  -1.0->-0.1, 3005 .  -1.0->-0.1, 3014 .  -1.0->-0.1, \n",
            "3021 .  -1.0->-0.1, 3022 .  -1.0->-0.1, 3032 .  -1.0->-0.1, 3245 .  -1.0->-0.1, 3246 .  -1.0->-0.1, 3247 .  -1.0->-0.1, 3248 .  -1.0->-0.1, \n",
            "3249 .  -1.0->-0.1, 3358 .  -1.0->-0.1, 3359 .  -1.0->-0.1, 3360 .  -1.0->-0.1, 3361 .  -1.0->-0.1, 3367 .  -1.0->-0.1, 3368 .  -1.0->-0.1, \n",
            "3369 .  -1.0->-0.1, 3376 .  -1.0->-0.1, 3377 .  -1.0->-0.1, 3378 .  -1.0->-0.1, 3379 .  -1.0->-0.1, 3386 .  -1.0->-0.1, 3387 .  -1.0->-0.1, \n",
            "3388 .  -1.0->-0.1, 3389 .  -1.0->-0.1, 3395 .  -1.0->-0.1, 3396 .  -1.0->-0.1, 3397 .  -1.0->-0.1, 3404 .  -1.0->-0.1, 3411 .  -1.0->-0.1, \n",
            "3412 .  -1.0->-0.1, 3413 .  -1.0->-0.1, 3424 .  -1.0->-0.1, 3425 .  -1.0->-0.1, 3431 .  -1.0->-0.1, 3438 .  -1.0->-0.1, 3445 .  -1.0->-0.1, \n",
            "3446 .  -1.0->-0.1, 3447 .  -1.0->-0.1, 3448 .  -1.0->-0.1, 3610 .  -1.0->-0.1, 3611 .  -1.0->-0.1, 3612 .  -1.0->-0.1, 3613 .  -1.0->-0.1, \n",
            "3614 .  -1.0->-0.1, 3615 .  -1.0->-0.1, 3616 .  -1.0->-0.1, 3619 .  -1.0->-0.1, 3623 .  -1.0->-0.1, 3624 .  -1.0->-0.1, 3625 .  -1.0->-0.1, \n",
            "3627 .  -1.0->-0.1, 3631 .  -1.0->-0.1, 3635 .  -1.0->-0.1, 3648 .  -1.0->-0.1, 3652 .  -1.0->-0.1, 3656 .  -1.0->-0.1, 3662 .  -1.0->-0.1, \n",
            "3672 .  -1.0->-0.1, 3679 .  -1.0->-0.1, 3686 .  -1.0->-0.1, 3690 .  -1.0->-0.1, 3691 .  -1.0->-0.1, 3692 .  -1.0->-0.1, 3694 .  -1.0->-0.1, \n",
            "3695 .  -1.0->-0.1, 3698 .  -1.0->-0.1, 3699 .  -1.0->-0.1, 3702 .  -1.0->-0.1, 3703 .  -1.0->-0.1, 3725 .  -1.0->-0.1, 3726 .  -1.0->-0.1, \n",
            "3727 .  -1.0->-0.1, 3882 .  -1.0->-0.1, 3888 .  -1.0->-0.1, 3907 .  -1.0->-0.1, 3908 .  -1.0->-0.1, 3917 .  -1.0->-0.1, 3918 .  -1.0->-0.1, \n",
            "3924 .  -1.0->-0.1, 3925 .  -1.0->-0.1, 3931 .  -1.0->-0.1, 3935 .  -1.0->-0.1, 3936 .  -1.0->-0.1, 3937 .  -1.0->-0.1, 3940 .  -1.0->-0.1, \n",
            "3944 .  -1.0->-0.1, 3948 .  -1.0->-0.1, 4102 .  -1.0->-0.1, 4108 .  -1.0->-0.1, 4194 .  -1.0->-0.1, 4195 .  -1.0->-0.1, 4200 .  -1.0->-0.1, \n",
            "4201 .  -1.0->-0.1, 4296 .  -1.0->-0.1, 4465 .  -1.0->-0.1, 4466 .  -1.0->-0.1, 4467 .  -1.0->-0.1, 4468 .  -1.0->-0.1, 4469 .  -1.0->-0.1, \n",
            "4470 .  -1.0->-0.1, 4490 .  -1.0->-0.1, 4536 .  -1.0->-0.1, 4537 .  -1.0->-0.1, 4538 .  -1.0->-0.1, 4539 .  -1.0->-0.1, 4540 .  -1.0->-0.1, \n",
            "4541 .  -1.0->-0.1, 4545 .  -1.0->-0.1, 4595 .  -1.0->-0.1, 4669 .  -1.0->-0.1, 4670 .  -1.0->-0.1, 4671 .  -1.0->-0.1, 4672 .  -1.0->-0.1, \n",
            "4680 .  -1.0->-0.1, /content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "/content/simplicial_neural_networks\n",
            "Parameter counts:\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "Total number of parameters: 14583\n",
            "[0.6988636363636364, 0.6994572591587517, 0.6998477929984779]\n",
            "/content/simplicial_neural_networks/experiments/output\n",
            "We set this random number:  0.38630708251312174\n",
            "Accuracy for 0-laplacian: 0.6680589430894309\n",
            "Accuracy for 1-laplacian: 0.6876905916585839\n",
            "Accuracy for 2-laplacian: 0.6973440626359286\n",
            "The maximum accuracy for 0 laplacian is: 0.6680589430894309 and its index is: 0 with coefficient 0.38630708251312174\n",
            "The maximum accuracy for 1 laplacian is: 0.6876905916585839 and its index is: 0 with coefficient 0.38630708251312174\n",
            "The maximum accuracy for 2 laplacian is: 0.6973440626359286 and its index is: 0 with coefficient 0.38630708251312174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0-laplacian accuracies\n",
        "for i in range(len(accuracies_for_0_laplacian)):\n",
        "  print(\"0-laplacian accuracy: \",accuracies_for_0_laplacian[i],\"for random number: \",random_numbers[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syWnD1_LDwbB",
        "outputId": "47b6596c-6606-46ac-c866-88d83cb71c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-laplacian accuracy:  0.6680589430894309 for random number:  0.38630708251312174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-laplacian accuracies\n",
        "for i in range(len(accuracies_for_1_laplacian)):\n",
        "  print(\"1-laplacian accuracy: \",accuracies_for_1_laplacian[i],\"for random number: \",random_numbers[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2nCKKuE0Kr",
        "outputId": "bae5c5dd-db49-44f4-a423-051bc24ac581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-laplacian accuracy:  0.6876905916585839 for random number:  0.38630708251312174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-laplacian accuracies\n",
        "for i in range(len(accuracies_for_2_laplacian)):\n",
        "  print(\"2-laplacian accuracy: \",accuracies_for_2_laplacian[i],\"for random number: \",random_numbers[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwYQsSE_E1Fj",
        "outputId": "2e2bc691-d273-43ca-d583-c8a271ac067c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-laplacian accuracy:  0.6973440626359286 for random number:  0.38630708251312174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max accuracy we got: \",max_accuracy0,max_accuracy1,max_accuracy2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N386ALRTFaDQ",
        "outputId": "61c594d7-ffc6-4d33-88af-87a8a0a3c51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max accuracy we got:  0.6680589430894309 0.6876905916585839 0.6973440626359286\n"
          ]
        }
      ]
    }
  ]
}