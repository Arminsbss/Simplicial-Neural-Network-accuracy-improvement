{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxAZTGrAn3ogn3kILhaf8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arminsbss/Simplicial-Neural-Network/blob/main/impute_citations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/stefaniaebli/simplicial_neural_networks.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeBWqxeTByZA",
        "outputId": "c9d8afaa-93b6-4de6-86eb-04c1110ceede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simplicial_neural_networks'...\n",
            "remote: Enumerating objects: 339, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 339 (delta 50), reused 48 (delta 48), pack-reused 280\u001b[K\n",
            "Receiving objects: 100% (339/339), 2.42 MiB | 6.09 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/simplicial_neural_networks/scnn\n",
        "# from simplicial_neural_networks import scnn\n",
        "import simplicial_neural_networks.scnn\n",
        "import simplicial_neural_networks.scnn.chebyshev\n"
      ],
      "metadata": {
        "id": "qMWXG34_UAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title scnn\n",
        "#scnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import simplicial_neural_networks.scnn.chebyshev\n",
        "def coo2tensor(A):\n",
        "    assert(sp.isspmatrix_coo(A))\n",
        "    idxs = torch.LongTensor(np.vstack((A.row, A.col)))\n",
        "    vals = torch.FloatTensor(A.data)\n",
        "    return torch.sparse_coo_tensor(idxs, vals, size = A.shape, requires_grad = False)\n",
        "\n",
        "class SimplicialConvolution(nn.Module):\n",
        "    def __init__(self, K, C_in, C_out, enable_bias = True, variance = 1.0, groups = 1):\n",
        "        assert groups == 1, \"Only groups = 1 is currently supported.\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert(C_in > 0)\n",
        "        assert(C_out > 0)\n",
        "        assert(K > 0)\n",
        "\n",
        "        self.C_in = C_in\n",
        "        self.C_out = C_out\n",
        "        self.K = K\n",
        "        self.enable_bias = enable_bias\n",
        "\n",
        "        self.theta = nn.parameter.Parameter(variance*torch.randn((self.C_out, self.C_in, self.K)))\n",
        "        if self.enable_bias:\n",
        "            self.bias = nn.parameter.Parameter(torch.zeros((1, self.C_out, 1)))\n",
        "        else:\n",
        "            self.bias = 0.0\n",
        "\n",
        "    def forward(self, L, x):\n",
        "        assert(len(L.shape) == 2)\n",
        "        assert(L.shape[0] == L.shape[1])\n",
        "\n",
        "        (B, C_in, M) = x.shape\n",
        "\n",
        "        assert(M == L.shape[0])\n",
        "        assert(C_in == self.C_in)\n",
        "\n",
        "        X = scnn.chebyshev.assemble(self.K, L, x)\n",
        "        y = torch.einsum(\"bimk,oik->bom\", (X, self.theta))\n",
        "        assert(y.shape == (B, self.C_out, M))\n",
        "\n",
        "        return y + self.bias\n",
        "\n",
        "# This class does not yet implement the\n",
        "# Laplacian-power-pre/post-composed with the coboundary. It can be\n",
        "# simulated by just adding more layers anyway, so keeping it simple\n",
        "# for now.\n",
        "#\n",
        "# Note: You can use this for a adjoints of coboundaries too. Just feed\n",
        "# a transposed D.\n",
        "class Coboundary(nn.Module):\n",
        "    def __init__(self, C_in, C_out, enable_bias = True, variance = 1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        assert(C_in > 0)\n",
        "        assert(C_out > 0)\n",
        "\n",
        "        self.C_in = C_in\n",
        "        self.C_out = C_out\n",
        "        self.enable_bias = enable_bias\n",
        "\n",
        "        self.theta = nn.parameter.Parameter(variance*torch.randn((self.C_out, self.C_in)))\n",
        "        if self.enable_bias:\n",
        "            self.bias = nn.parameter.Parameter(torch.zeros((1, self.C_out, 1)))\n",
        "        else:\n",
        "            self.bias = 0.0\n",
        "\n",
        "    def forward(self, D, x):\n",
        "        assert(len(D.shape) == 2)\n",
        "\n",
        "        (B, C_in, M) = x.shape\n",
        "\n",
        "        assert(D.shape[1] == M)\n",
        "        assert(C_in == self.C_in)\n",
        "\n",
        "        N = D.shape[0]\n",
        "\n",
        "        # This is essentially the equivalent of chebyshev.assemble for\n",
        "        # the convolutional modules.\n",
        "        X = []\n",
        "        for b in range(0, B):\n",
        "            X12 = []\n",
        "            for c_in in range(0, self.C_in):\n",
        "                X12.append(D.mm(x[b, c_in, :].unsqueeze(1)).transpose(0,1)) # D.mm(x[b, c_in, :]) has shape Nx1\n",
        "            X12 = torch.cat(X12, 0)\n",
        "\n",
        "            assert(X12.shape == (self.C_in, N))\n",
        "            X.append(X12.unsqueeze(0))\n",
        "\n",
        "        X = torch.cat(X, 0)\n",
        "        assert(X.shape == (B, self.C_in, N))\n",
        "\n",
        "        y = torch.einsum(\"oi,bin->bon\", (self.theta, X))\n",
        "        assert(y.shape == (B, self.C_out, N))\n",
        "\n",
        "        return y + self.bias"
      ],
      "metadata": {
        "id": "_0wznF4nD_vA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title chebyshef\n",
        "#chebyshef\n",
        "import torch\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spl\n",
        "import numpy as np\n",
        "def normalize(L, half_interval = False):\n",
        "    assert(sp.isspmatrix(L))\n",
        "    M = L.shape[0]\n",
        "    assert(M == L.shape[1])\n",
        "    topeig = spl.eigsh(L, k=1, which=\"LM\", return_eigenvectors = False)[0]\n",
        "    #print(\"Topeig = %f\" %(topeig))\n",
        "\n",
        "    ret = L.copy()\n",
        "    if half_interval:\n",
        "        ret *= 1.0/topeig\n",
        "    else:\n",
        "        ret *= 2.0/topeig\n",
        "        ret.setdiag(ret.diagonal(0) - np.ones(M), 0)\n",
        "\n",
        "    return ret\n",
        "\n",
        "def assemble(K, L, x):\n",
        "    (B, C_in, M) = x.shape\n",
        "    assert(L.shape[0] == M)\n",
        "    assert(L.shape[0] == L.shape[1])\n",
        "    assert(K > 0)\n",
        "\n",
        "    X = []\n",
        "    for b in range(0, B):\n",
        "        X123 = []\n",
        "        for c_in in range(0, C_in):\n",
        "            X23 = []\n",
        "            X23.append(x[b, c_in, :].unsqueeze(1)) # Constant, k = 0 term.\n",
        "\n",
        "            if K > 1:\n",
        "                X23.append(L.mm(X23[0]))\n",
        "            for k in range(2, K):\n",
        "                X23.append(2*(L.mm(X23[k-1])) - X23[k-2])\n",
        "\n",
        "            X23 = torch.cat(X23, 1)\n",
        "            assert(X23.shape == (M, K))\n",
        "            X123.append(X23.unsqueeze(0))\n",
        "\n",
        "        X123 = torch.cat(X123, 0)\n",
        "        assert(X123.shape == (C_in, M, K))\n",
        "        X.append(X123.unsqueeze(0))\n",
        "\n",
        "    X = torch.cat(X, 0)\n",
        "    assert(X.shape == (B, C_in, M, K))\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "i1w5OlG9EQiX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MySCNN(nn.Module):\n",
        "    def __init__(self, colors = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        assert(colors > 0)\n",
        "        self.colors = colors\n",
        "\n",
        "        num_filters = 30 #20\n",
        "        variance = 0.01 #0.001\n",
        "\n",
        "        # Degree 0 convolutions.\n",
        "        self.C0_1 = scnn.scnn.SimplicialConvolution(5, self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C0_2 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C0_3 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, self.colors, variance=variance)\n",
        "\n",
        "        # Degree 1 convolutions.\n",
        "        self.C1_1 = scnn.scnn.SimplicialConvolution(5, self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C1_2 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C1_3 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, self.colors, variance=variance)\n",
        "\n",
        "        # Degree 2 convolutions.\n",
        "        self.C2_1 = scnn.scnn.SimplicialConvolution(5, self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C2_2 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, num_filters*self.colors, variance=variance)\n",
        "        self.C2_3 = scnn.scnn.SimplicialConvolution(5, num_filters*self.colors, self.colors, variance=variance)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, Ls, Ds, adDs, xs):\n",
        "        assert(len(xs) == 3) # The three degrees are fed together as a list.\n",
        "\n",
        "        assert(len(Ls) == len(Ds))\n",
        "        Ms = [L.shape[0] for L in Ls]\n",
        "        Ns = [D.shape[0] for D in Ds]\n",
        "\n",
        "        Bs = [x.shape[0] for x in xs]\n",
        "        C_ins = [x.shape[1] for x in xs]\n",
        "        Ms = [x.shape[2] for x in xs]\n",
        "\n",
        "        assert(Ms == [D.shape[1] for D in Ds])\n",
        "        assert(Ms == [L.shape[1] for L in Ls])\n",
        "        assert([adD.shape[0] for adD in adDs] == [D.shape[1] for D in Ds])\n",
        "        assert([adD.shape[1] for adD in adDs] == [D.shape[0] for D in Ds])\n",
        "\n",
        "        assert(Bs == len(Bs)*[Bs[0]])\n",
        "        assert(C_ins == len(C_ins)*[C_ins[0]])\n",
        "\n",
        "        out0_1 = self.C0_1(Ls[0], xs[0]) #+ self.D10_1(xs[1])\n",
        "        out1_1 = self.C1_1(Ls[1], xs[1]) #+ self.D01_1(xs[0]) + self.D21_1(xs[2])\n",
        "        out2_1 = self.C2_1(Ls[2], xs[2]) #+ self.D12_1(xs[1])\n",
        "\n",
        "        out0_2 = self.C0_2(Ls[0], nn.LeakyReLU()(out0_1)) #+ self.D10_2(nn.LeakyReLU()(out1_1))\n",
        "        out1_2 = self.C1_2(Ls[1], nn.LeakyReLU()(out1_1)) #+ self.D01_2(nn.LeakyReLU()(out0_1)) + self.D21_2(nn.LeakyReLU()(out2_1))\n",
        "        out2_2 = self.C2_2(Ls[2], nn.LeakyReLU()(out2_1)) #+ self.D12_2(nn.LeakyReLU()(out1_1))\n",
        "\n",
        "        out0_3 = self.C0_3(Ls[0], nn.LeakyReLU()(out0_2)) #+ self.D10_3(nn.LeakyReLU()(out1_2))\n",
        "        out1_3 = self.C1_3(Ls[1], nn.LeakyReLU()(out1_2)) #+ self.D01_3(nn.LeakyReLU()(out0_2)) + self.D21_2(nn.LeakyReLU()(out2_2))\n",
        "        out2_3 = self.C2_3(Ls[2], nn.LeakyReLU()(out2_2)) #+ self.D12_3(nn.LeakyReLU()(out1_2))\n",
        "\n",
        "        #return [out0_3, torch.zeros_like(xs[1]), torch.zeros_like(xs[2])]\n",
        "        #return [torch.zeros_like(xs[0]), out1_3, torch.zeros_like(xs[2])]\n",
        "        return [out0_3, out1_3, out2_3]"
      ],
      "metadata": {
        "id": "AU5tY376B18q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('.')"
      ],
      "metadata": {
        "id": "e3Ka3WpgZsJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/simplicial_neural_networks/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hrg9l-T1jze",
        "outputId": "73cfcf9f-dcf8-402c-92a3-6d3b9f719539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simplicial_neural_networks/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "WIV2-OfZFSL2",
        "outputId": "10708dc4-7186-4706-a875-972039975737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5cd57e36e8d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'logdir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
        "laplacians = np.load('150250_laplacians.npy',allow_pickle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37D6K1Qxhlka",
        "outputId": "51b86b6a-71b9-4c1b-fc92-852120e734b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "laplacians[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRI9_HpE6eoC",
        "outputId": "e321f3f9-ec26-4030-a247-4f06855e1457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1474x1474 sparse matrix of type '<class 'numpy.float32'>'\n",
              "\twith 25466 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch._C import float32\n",
        "for i in range(len(laplacians[1])):\n",
        "  if type(i)==float32:\n",
        "    indices = laplacians[1]\n",
        "\n",
        "indices = laplacians[1].nonzero()\n",
        "laplacians[1][indices] /= 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "sgZm42Y6h5tB",
        "outputId": "d7633607-0c1b-4146-c9d7-853bd1181df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-29e4f2eb4310>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from torch._C import float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplacians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaplacians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    346\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(laplacians[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WznNSjCxjnmd",
        "outputId": "cd62f560-0ccd-4889-d6aa-d8d4af4b0597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._coo.coo_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(laplacians)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5deVrDVTAT-",
        "outputId": "233b3320-f95c-45ab-c420-dcce9908ac0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<352x352 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 3300 stored elements in COOrdinate format>\n",
            " <1474x1474 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 25466 stored elements in COOrdinate format>\n",
            " <3285x3285 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 4697 stored elements in COOrdinate format>\n",
            " <5019x5019 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 5419 stored elements in COOrdinate format>\n",
            " <5559x5559 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 5601 stored elements in COOrdinate format>\n",
            " <4547x4547 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 4547 stored elements in COOrdinate format>\n",
            " <2732x2732 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 2732 stored elements in COOrdinate format>\n",
            " <1175x1175 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 1175 stored elements in COOrdinate format>\n",
            " <343x343 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 343 stored elements in COOrdinate format>\n",
            " <61x61 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 61 stored elements in COOrdinate format>\n",
            " <5x5 sparse matrix of type '<class 'numpy.float32'>'\n",
            " \twith 5 stored elements in COOrdinate format>       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('my_array.npy', laplacians)\n"
      ],
      "metadata": {
        "id": "cGJiKYhvkG67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnzQGe23BJ-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "116fd1df-4a45-4b85-9770-7dbe72c10b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "/content/simplicial_neural_networks\n",
            "Parameter counts:\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "Total number of parameters: 14583\n",
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "[0.6988636363636364, 0.6994572591587517, 0.6998477929984779]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2d897450f28a>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-2d897450f28a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mlosslogf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mname_networks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C0_1,C0_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C0_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C1_1,C1_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C1_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C2_1,C2_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C2_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losslogf' is not defined"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    torch.manual_seed(1337)\n",
        "    np.random.seed(1337)\n",
        "\n",
        "\n",
        "    prefix = sys.argv[1] ##input\n",
        "\n",
        "    logdir = sys.argv[2] ##output\n",
        "    starting_node=150250\n",
        "    percentage_missing_values=30\n",
        "    cuda = False\n",
        "\n",
        "    topdim = 2\n",
        "    %cd '/content/simplicial_neural_networks/data/s2_3_collaboration_complex'\n",
        "\n",
        "    laplacians = np.load('{}_laplacians.npy'.format(starting_node),allow_pickle=True)\n",
        "    boundaries = np.load('{}_boundaries.npy'.format(starting_node),allow_pickle=True)\n",
        "    %cd /content/simplicial_neural_networks\n",
        "\n",
        "\n",
        "    Ls =[coo2tensor(chebyshev.normalize(laplacians[i],half_interval=True)) for i in range(topdim+1)] #####scnn.chebyshev.normalize ?\n",
        "    Ds=[coo2tensor(boundaries[i].transpose()) for i in range(topdim+1)]\n",
        "    adDs=[coo2tensor(boundaries[i]) for i in range(topdim+1)]\n",
        "\n",
        "\n",
        "    network = MySCNN(colors = 1)\n",
        "\n",
        "\n",
        "    learning_rate = 0.001\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
        "    criterion = nn.L1Loss(reduction=\"sum\")\n",
        "    #criterion = nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    num_params = 0\n",
        "    print(\"Parameter counts:\")\n",
        "    for param in network.parameters():\n",
        "        p = np.array(param.shape, dtype=int).prod()\n",
        "        print(p)\n",
        "        num_params += p\n",
        "    print(\"Total number of parameters: %d\" %(num_params))\n",
        "\n",
        "    %cd /content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
        "    masks_all_deg = np.load('{}_percentage_{}_known_values.npy'.format(starting_node,percentage_missing_values),allow_pickle=True) ## positive mask= indices that we keep ##1 mask #entries 0 degree\n",
        "    masks=[list(masks_all_deg[i].values()) for i in range(len(masks_all_deg))]\n",
        "    # losslogf = open(\"%s/loss.txt\" %(logdir), \"w\")\n",
        "\n",
        "    cochain_target_alldegs = []\n",
        "    signal = np.load('{}_cochains.npy'.format(starting_node),allow_pickle=True)\n",
        "    raw_data=[list(signal[i].values()) for i in range(len(signal))]\n",
        "    for d in range(0, topdim+1):\n",
        "        cochain_target = torch.zeros((batch_size, 1, len(raw_data[d])), dtype=torch.float, requires_grad = False)\n",
        "        for i in range(0, batch_size):\n",
        "            cochain_target[i, 0, :] = torch.tensor(raw_data[d], dtype=torch.float, requires_grad = False)\n",
        "\n",
        "        cochain_target_alldegs.append(cochain_target)\n",
        "\n",
        "    cochain_input_alldegs = []\n",
        "    signal = np.load('{}_percentage_{}_input_damaged.npy'.format(starting_node,percentage_missing_values),allow_pickle=True)\n",
        "    raw_data=[list(signal[i].values()) for i in range(len(signal))]\n",
        "    for d in range(0, topdim+1):\n",
        "\n",
        "        cochain_input = torch.zeros((batch_size, 1, len(raw_data[d])), dtype=torch.float, requires_grad = False)\n",
        "\n",
        "        for i in range(0, batch_size):\n",
        "            cochain_input[i, 0, :] = torch.tensor(raw_data[d], dtype=torch.float, requires_grad = False)\n",
        "\n",
        "        cochain_input_alldegs.append(cochain_input)\n",
        "\n",
        "    #cochain_target_alldegs[0] = torch.zeros_like(cochain_target_alldegs[0])\n",
        "    #cochain_target_alldegs[2] = torch.zeros_like(cochain_target_alldegs[2])\n",
        "\n",
        "    #cochain_input_alldegs[0] = torch.zeros_like(cochain_input_alldegs[0])\n",
        "    #cochain_input_alldegs[2] = torch.zeros_like(cochain_input_alldegs[2])\n",
        "\n",
        "    print([float(len(masks[d]))/float(len(cochain_target_alldegs[d][0,0,:])) for d in range(0,2+1)])\n",
        "\n",
        "    for i in range(0, 1000):\n",
        "        xs = [cochain_input.clone() for cochain_input in cochain_input_alldegs]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        ys = network(Ls, Ds, adDs, xs)\n",
        "\n",
        "        loss = torch.FloatTensor([0.0])\n",
        "        for b in range(0, batch_size):\n",
        "            for d in range(0, topdim+1):\n",
        "                loss += criterion(ys[d][b, 0, masks[d]], cochain_target_alldegs[d][b, 0, masks[d]])\n",
        "\n",
        "        detached_ys = [ys[d].detach() for d in range(0, topdim+1)]\n",
        "\n",
        "        # if np.mod(i, 10) == 0:\n",
        "        #     for d in range(0,topdim+1):\n",
        "        #         np.savetxt(\"%s/output_%d_%d.txt\" %(logdir, i, d), detached_ys[d][0,0,:])\n",
        "\n",
        "        for d in range(0, topdim+1):\n",
        "            predictionlogf = open(\"%s/prediction_%d_%d.txt\" %(logdir, i, d), \"w\")\n",
        "            actuallogf = open(\"%s/actual_%d_%d.txt\" %(logdir, i, d), \"w\")\n",
        "\n",
        "            for b in range(0, batch_size):\n",
        "                for y in detached_ys[d][b, 0, masks[d]]:\n",
        "                    predictionlogf.write(\"%f \" %(y))\n",
        "                predictionlogf.write(\"\\n\")\n",
        "                for x in cochain_target_alldegs[d][b, 0, masks[d]]:\n",
        "                    actuallogf.write(\"%f \" %(x))\n",
        "                actuallogf.write(\"\\n\")\n",
        "            predictionlogf.close()\n",
        "            actuallogf.close()\n",
        "\n",
        "\n",
        "        losslogf.write(\"%d %f\\n\" %(i, loss.item()))\n",
        "        losslogf.flush()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # losslogf.close()\n",
        "\n",
        "    name_networks=['C0_1,C0_2','C0_3','C1_1,C1_2','C1_3', 'C2_1,C2_2','C2_3']\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_networks=['C0_1,C0_2','C0_3','C1_1,C1_2','C1_3', 'C2_1,C2_2','C2_3']\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "6nma7_OxIpVT",
        "outputId": "30be26cb-92f7-4519-810b-6344e1552334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "/content/simplicial_neural_networks\n",
            "Parameter counts:\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "150\n",
            "30\n",
            "4500\n",
            "30\n",
            "150\n",
            "1\n",
            "Total number of parameters: 14583\n",
            "/content/simplicial_neural_networks/data/s2_3_collaboration_complex\n",
            "[0.6988636363636364, 0.6994572591587517, 0.6998477929984779]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0f6aaf7a9092>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-2d897450f28a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0ce57aea32f6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Ls, Ds, adDs, xs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mout0_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC0_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout0_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ self.D10_2(nn.LeakyReLU()(out1_1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mout1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ self.D01_2(nn.LeakyReLU()(out0_1)) + self.D21_2(nn.LeakyReLU()(out2_1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mout2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ self.D12_2(nn.LeakyReLU()(out1_1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout0_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC0_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout0_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ self.D10_3(nn.LeakyReLU()(out1_2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/simplicial_neural_networks/scnn/scnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, L, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_in\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchebyshev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bimk,oik->bom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/simplicial_neural_networks/scnn/chebyshev.py\u001b[0m in \u001b[0;36massemble\u001b[0;34m(K, L, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mX23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX23\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mX23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX23\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX23\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}